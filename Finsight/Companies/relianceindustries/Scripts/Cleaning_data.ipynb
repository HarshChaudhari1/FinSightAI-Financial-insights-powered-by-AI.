{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Blzj3DHECR-t",
        "outputId": "36ec61a3-abb8-46e4-870f-0a283b84fd5e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Starting Data Cleaning Process for Reliance ---\n",
            "Processing file: relianceidustriesProfitnLoss.csv\n",
            "Cleaned columns: ['date', 'revenue_from_operations_net', 'other_income', 'total_revenue', 'total_expenses', 'profit_loss_before_exceptional_extraordinary_items_and_tax', 'profit_loss_before_tax', 'profit_loss_for_the_period', 'basic_eps', 'diluted_eps']\n",
            "Date column type: datetime64[ns]\n",
            "------------------------------\n",
            "Successfully cleaned and saved to ./cleaned_reliance_relianceidustriesprofitnloss.csv\n",
            "\n",
            "Processing file: relianceindustries_balance.csv\n",
            "Cleaned columns: ['date', 'equity_share_capital', 'total_share_capital', 'reserves_and_surplus', 'total_reserves_and_surplus', 'total_shareholders_funds', 'long_term_borrowings', 'deferred_tax_liabilities_net', 'other_long_term_liabilities', 'long_term_provisions', 'total_non_current_liabilities', 'short_term_borrowings', 'trade_payables', 'other_current_liabilities', 'short_term_provisions', 'total_current_liabilities', 'total_capital_and_liabilities', 'tangible_assets', 'intangible_assets', 'capital_work_in_progress', 'other_assets', 'fixed_assets', 'non_current_investments', 'deferred_tax_assets_net', 'long_term_loans_and_advances', 'other_non_current_assets', 'total_non_current_assets', 'current_investments', 'inventories', 'trade_receivables', 'cash_and_cash_equivalents', 'short_term_loans_and_advances', 'othercurrentassets', 'total_current_assets', 'total_assets']\n",
            "Date column type: datetime64[ns]\n",
            "------------------------------\n",
            "Successfully cleaned and saved to ./cleaned_reliance_relianceindustries_balance.csv\n",
            "\n",
            "Processing file: relianceindustrues_cashflow.csv\n",
            "Cleaned columns: ['date', 'net_profit_loss_before_extraordinary_items_and_tax', 'net_cashflow_from_operating_activities', 'net_cash_used_in_investing_activities', 'net_cash_used_from_financing_activities', 'net_inc_dec_in_cash_and_cash_equivalents', 'cash_and_cash_equivalents_end_of_year']\n",
            "Date column type: datetime64[ns]\n",
            "------------------------------\n",
            "Successfully cleaned and saved to ./cleaned_reliance_relianceindustrues_cashflow.csv\n",
            "\n",
            "Processing file: relianceindustries_Ratio.csv\n",
            "Cleaned columns: ['date', 'basic_eps', 'book_value_inclrevalreserve_share', 'revenue_from_operations_share', 'pbdit_share', 'pbit_share', 'pbt_share', 'net_profit_share', 'pbdit_margin', 'pbit_margin', 'pbt_margin', 'net_profit_margin', 'return_on_networth_equity', 'return_on_capital_employed', 'return_on_assets', 'total_debt_equity', 'asset_turnover_ratio', 'current_ratio', 'quick_ratio', 'inventory_turnover_ratio', 'dividend_payout_ratio', 'dividend_payout_ratio', 'earnings_retention_ratio', 'cash_earnings_retention_ratio', 'enterprise_value', 'ev_net_operating_revenue', 'ev_ebitda', 'marketcap_net_operating_revenue', 'price_bv', 'price_net_operating_revenue', 'earnings_yield']\n",
            "Date column type: datetime64[ns]\n",
            "------------------------------\n",
            "Successfully cleaned and saved to ./cleaned_reliance_relianceindustries_ratio.csv\n",
            "\n",
            "Processing file: relianceindustriesQuater.csv\n",
            "Cleaned columns: ['date', 'net_sales_income_from_operations', 'other_operating_income', 'total_income_from_operations', 'p_l_before_tax', 'net_profit_for_the_period', 'basic_eps', 'diluted_eps']\n",
            "Date column type: datetime64[ns]\n",
            "------------------------------\n",
            "Successfully cleaned and saved to ./cleaned_reliance_relianceindustriesquater.csv\n",
            "\n",
            "Processing file: RELIANCE  Prices.csv\n",
            "Cleaned columns: ['date', 'close', 'high', 'low', 'open', 'volume', 'company', 'sma_10', 'ema_20', 'rsi_14', 'macd_12_26_9', 'macdh_12_26_9', 'macds_12_26_9', 'bbl_20_2_0', 'bbm_20_2_0', 'bbu_20_2_0', 'bbb_20_2_0', 'bbp_20_2_0', 'target']\n",
            "Date column type: datetime64[ns]\n",
            "------------------------------\n",
            "Successfully cleaned and saved to ./cleaned_reliance_reliance__prices.csv\n",
            "\n",
            "Processing file: reliance_news.csv\n",
            "Cleaned columns: ['date', 'title', 'link', 'summary', 'text']\n",
            "Date column type: datetime64[ns]\n",
            "------------------------------\n",
            "Successfully cleaned and saved to ./cleaned_reliance_reliance_news.csv\n",
            "\n",
            "Processing file: RelianceReddit.csv\n",
            "Cleaned columns: ['date', 'news', 'top_comments', 'text']\n",
            "Date column type: datetime64[ns]\n",
            "------------------------------\n",
            "Successfully cleaned and saved to ./cleaned_reliance_reliancereddit.csv\n",
            "\n",
            "--- Data Cleaning Process Completed ---\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import re\n",
        "\n",
        "def clean_financial_data(df, date_col_name='Date'):\n",
        "    new_columns = {}\n",
        "    for col in df.columns:\n",
        "        clean_col = re.sub(r'\\s*\\(.*\\)\\s*', '', col)\n",
        "        clean_col = re.sub(r'[^a-zA-Z0-9]+', '_', clean_col).lower()\n",
        "        clean_col = clean_col.strip('_')\n",
        "        new_columns[col] = clean_col\n",
        "    df = df.rename(columns=new_columns)\n",
        "\n",
        "    date_col_name_cleaned = new_columns.get(date_col_name, str(date_col_name).lower())\n",
        "\n",
        "    if date_col_name_cleaned in df.columns:\n",
        "        df[date_col_name_cleaned] = pd.to_datetime(df[date_col_name_cleaned], errors='coerce')\n",
        "        df = df.rename(columns={date_col_name_cleaned: 'date'})\n",
        "\n",
        "    if 'date' in df.columns:\n",
        "        df = df.sort_values(by='date').reset_index(drop=True)\n",
        "    df.ffill(inplace=True)\n",
        "\n",
        "    print(f\"Cleaned columns: {df.columns.tolist()}\")\n",
        "    print(f\"Date column type: {df['date'].dtype if 'date' in df.columns else 'Not found'}\")\n",
        "    print(\"-\" * 30)\n",
        "\n",
        "    return df\n",
        "\n",
        "def clean_text_data(df, date_col_name):\n",
        "\n",
        "    df.columns = [col.strip().lower() for col in df.columns]\n",
        "\n",
        "    date_col_name_lower = date_col_name.lower()\n",
        "\n",
        "    if date_col_name_lower in df.columns:\n",
        "        df = df.rename(columns={date_col_name_lower: 'date'})\n",
        "        df['date'] = pd.to_datetime(df['date'], errors='coerce')\n",
        "\n",
        "    text_cols = []\n",
        "    if 'title' in df.columns and 'summary' in df.columns: # News data\n",
        "        text_cols = ['title', 'summary']\n",
        "    elif 'news' in df.columns and 'top_comments' in df.columns: # Reddit data\n",
        "        text_cols = ['news', 'top_comments']\n",
        "\n",
        "    df.dropna(subset=['date'] + text_cols, inplace=True)\n",
        "\n",
        "    if 'title' in text_cols and 'summary' in text_cols:\n",
        "        df['text'] = df['title'] + \". \" + df['summary']\n",
        "    elif 'news' in text_cols and 'top_comments' in text_cols:\n",
        "        df['text'] = df['news'] + \". \" + df['top_comments']\n",
        "\n",
        "    print(f\"Cleaned columns: {df.columns.tolist()}\")\n",
        "    print(f\"Date column type: {df['date'].dtype if 'date' in df.columns else 'Not found'}\")\n",
        "    print(\"-\" * 30)\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "def main():\n",
        "\n",
        "    files_to_clean = {\n",
        "        'relianceidustriesProfitnLoss.csv': {'type': 'financial', 'date_col': 'Date'},\n",
        "        'relianceindustries_balance.csv': {'type': 'financial', 'date_col': 'Date'},\n",
        "        'relianceindustrues_cashflow.csv': {'type': 'financial', 'date_col': 'Date'},\n",
        "        'relianceindustries_Ratio.csv': {'type': 'financial', 'date_col': 'Date'},\n",
        "        'relianceindustriesQuater.csv': {'type': 'financial', 'date_col': 'Date'},\n",
        "        'RELIANCE  Prices.csv': {'type': 'financial', 'date_col': 'date'},\n",
        "        'reliance_news.csv': {'type': 'text', 'date_col': 'publishedAt'},\n",
        "        'RelianceReddit.csv': {'type': 'text', 'date_col': 'date'},\n",
        "    }\n",
        "\n",
        "    output_dir = './'\n",
        "\n",
        "    print(\"Starting Data Cleaning Process for Reliance\")\n",
        "\n",
        "    for filename, params in files_to_clean.items():\n",
        "        try:\n",
        "            print(f\"Processing file: {filename}\")\n",
        "\n",
        "\n",
        "            df = pd.read_csv(filename)\n",
        "\n",
        "            if params['type'] == 'financial':\n",
        "                cleaned_df = clean_financial_data(df, date_col_name=params['date_col'])\n",
        "            elif params['type'] == 'text':\n",
        "                cleaned_df = clean_text_data(df, date_col_name=params['date_col'])\n",
        "            else:\n",
        "                print(f\"Warning: No cleaning type defined for {filename}. Skipping.\")\n",
        "                continue\n",
        "\n",
        "            output_filename = f\"cleaned_reliance_{filename.lower().replace(' ', '_')}\"\n",
        "            output_path = os.path.join(output_dir, output_filename)\n",
        "            cleaned_df.to_csv(output_path, index=False)\n",
        "            print(f\"Successfully cleaned and saved to {output_path}\\n\")\n",
        "\n",
        "        except FileNotFoundError:\n",
        "            print(f\"Error: The file {filename} was not found. Please check the path.\")\n",
        "        except Exception as e:\n",
        "            print(f\"An error occurred while processing {filename}: {e}\")\n",
        "\n",
        "    print(\"--- Data Cleaning Process Completed ---\")\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UjT3ZmGoCrwt"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "name": "Welcome To Colab",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
