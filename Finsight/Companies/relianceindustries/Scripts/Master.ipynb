{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UjT3ZmGoCrwt",
        "outputId": "3378607f-5b5a-4fab-f6d5-2670d272052f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Starting Master Dataset Creation for Reliance Industries ---\n",
            "Loading base price data: cleaned_reliance_reliance__prices.csv\n",
            "Error: A required file was not found - None.\n",
            "Please ensure all previous cleaning and sentiment analysis steps were completed successfully.\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "def create_master_dataset():\n",
        "\n",
        "    print(\"Starting Master Dataset Creation for Reliance Industries \") \n",
        "\n",
        "    prices_file = 'cleaned_reliance_reliance__prices.csv' # Base\n",
        "\n",
        "    news_sentiment_file = 'reliance_news_with_sentiment.csv' \n",
        "    reddit_sentiment_file = 'reliance_reddit_with_sentiment.csv' \n",
        "\n",
        "    financial_files = {\n",
        "        'profit_loss': 'cleaned_reliance_relianceidustriesprofitnloss.csv',\n",
        "        'balance_sheet': 'cleaned_reliance_relianceindustries_balance.csv',\n",
        "        'cash_flow': 'cleaned_reliance_relianceindustrues_cashflow.csv',\n",
        "        'ratios': 'cleaned_reliance_relianceindustries_ratio.csv',\n",
        "        'quarterly': 'cleaned_reliance_relianceindustriesquater.csv'\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        print(f\"Loading base price data: {prices_file}\")\n",
        "        if not os.path.exists(prices_file):\n",
        "            raise FileNotFoundError(f\"Base price data file not found: {prices_file}\")\n",
        "\n",
        "        master_df = pd.read_csv(prices_file)\n",
        "        master_df['date'] = pd.to_datetime(master_df['date'])\n",
        "        master_df.sort_values('date', inplace=True)\n",
        "        print(f\"Base data loaded. Shape: {master_df.shape}\")\n",
        "\n",
        "        print(\"\\nProcessing sentiment data...\")\n",
        "\n",
        "        if os.path.exists(news_sentiment_file):\n",
        "            news_df = pd.read_csv(news_sentiment_file)\n",
        "            news_df['date'] = pd.to_datetime(news_df['date'])\n",
        "            news_agg = news_df.groupby('date')['sentiment_score'].mean().reset_index()\n",
        "            news_agg = news_agg.rename(columns={'sentiment_score': 'news_sentiment_avg'})\n",
        "            master_df = pd.merge(master_df, news_agg, on='date', how='left')\n",
        "            print(f\"News sentiment data merged from {news_sentiment_file}.\")\n",
        "        else:\n",
        "            print(f\"Warning: News sentiment file '{news_sentiment_file}' not found. Skipping news sentiment merge.\")\n",
        "            master_df['news_sentiment_avg'] = 0.0 \n",
        "\n",
        "        if os.path.exists(reddit_sentiment_file):\n",
        "            reddit_df = pd.read_csv(reddit_sentiment_file)\n",
        "            reddit_df['date'] = pd.to_datetime(reddit_df['date'])\n",
        "            reddit_agg = reddit_df.groupby('date')['sentiment_score'].mean().reset_index()\n",
        "            reddit_agg = reddit_agg.rename(columns={'sentiment_score': 'reddit_sentiment_avg'})\n",
        "            master_df = pd.merge(master_df, reddit_agg, on='date', how='left')\n",
        "            print(f\"Reddit sentiment data merged from {reddit_sentiment_file}.\")\n",
        "        else:\n",
        "            print(f\"Warning: Reddit sentiment file '{reddit_sentiment_file}' not found. Skipping Reddit sentiment merge.\")\n",
        "            master_df['reddit_sentiment_avg'] = 0.0 \n",
        "\n",
        "        master_df['news_sentiment_avg'].fillna(0, inplace=True)\n",
        "        master_df['reddit_sentiment_avg'].fillna(0, inplace=True)\n",
        "        print(\"Sentiment data merge process completed.\")\n",
        "        print(f\"Shape after sentiment merge: {master_df.shape}\")\n",
        "\n",
        "        print(\"\\nProcessing and merging financial data...\")\n",
        "        for name, file_path in financial_files.items():\n",
        "            print(f\"- Merging {name} data from {file_path}\")\n",
        "            if os.path.exists(file_path):\n",
        "                fin_df = pd.read_csv(file_path)\n",
        "                fin_df['date'] = pd.to_datetime(fin_df['date'])\n",
        "                fin_df.sort_values('date', inplace=True)\n",
        "\n",
        "                cols_to_drop = [col for col in fin_df.columns if col in master_df.columns and col != 'date']\n",
        "                fin_df = fin_df.drop(columns=cols_to_drop)\n",
        "\n",
        "\n",
        "                master_df = pd.merge_asof(master_df, fin_df, on='date', direction='backward')\n",
        "                print(f\" Shape after merging {name}: {master_df.shape}\")\n",
        "            else:\n",
        "                print(f\" Warning: Financial file '{file_path}' not found. Skipping {name} merge.\")\n",
        "\n",
        "        print(\"\\nFinalizing the master dataset...\")\n",
        "        master_df.dropna(inplace=True)\n",
        "\n",
        "        output_file = 'reliance_master_dataset.csv'\n",
        "        master_df.to_csv(output_file, index=False)\n",
        "\n",
        "        print(f\"\\nMaster dataset created successfully!\")\n",
        "        print(f\"Final shape: {master_df.shape}\")\n",
        "        print(f\"Saved to: {output_file}\")\n",
        "\n",
        "    except FileNotFoundError as e:\n",
        "        print(f\"Error: A required file was not found - {e.filename}.\")\n",
        "        print(\"Please ensure all previous cleaning and sentiment analysis steps were completed successfully.\")\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred during master dataset creation: {e}\")\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    create_master_dataset()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dkdT3dDHKcwy"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "name": "Welcome To Colab",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
